{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text Processing on Haptik Dataset\n",
    "#### We import all the packages required for all the processing required like data cleaning data prerocessing,building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#future imports\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "#Data Cleaning packages\n",
    "from pandas import read_csv, Series\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#timeit Decorator\n",
    "import time                                                \n",
    "\n",
    "def timeit(method):\n",
    "    \n",
    "    '''defined a function timeit\n",
    "    for finding the time taken to \n",
    "    execute the function'''\n",
    "    \n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'load_dataset'  313.93 ms\n",
      "'load_dataset'  32.34 ms\n"
     ]
    }
   ],
   "source": [
    "@timeit\n",
    "def load_dataset(filepath):\n",
    "    \n",
    "    '''defined a function load_dataset\n",
    "    for loading the csv files from\n",
    "    location '''\n",
    "    \n",
    "    dataset = read_csv(filepath, encoding = 'UTF-8' )\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train = load_dataset('./haptik/haptik_train_data.csv')\n",
    "\n",
    "test = load_dataset('./haptik/haptik_test_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'feature_target'  0.65 ms\n",
      "'feature_target'  0.51 ms\n"
     ]
    }
   ],
   "source": [
    "#separating feature and target variable\n",
    "@timeit\n",
    "def feature_target(df):\n",
    "    \n",
    "    '''defined a function feature_target\n",
    "    for separating the features and the \n",
    "    target variables from our dataset '''\n",
    "    \n",
    "    feature = df.iloc[:,0]\n",
    "    target = df.iloc[:,1:]\n",
    "    return feature, target\n",
    "\n",
    "X_train, y_train = feature_target(train)\n",
    "X_test, y_test = feature_target(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kakarot/anaconda2/envs/py27/lib/python2.7/site-packages/pandas/core/generic.py:3786: UserWarning: the \"axis\" argument is deprecated and will be removed inv0.13; this argument has no effect\n",
      "  warn('the \"axis\" argument is deprecated and will be removed in'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'encode'  544.93 ms\n",
      "'encode'  99.68 ms\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding for changing the categorical target variable to binary target variable(numerical)\n",
    "#do this on both train and test target variable i.e y_train ,y_test\n",
    "@timeit\n",
    "def encode(target):\n",
    "    \n",
    "    '''defined a function encode\n",
    "    to perform one hot encoding  on\n",
    "    the target categorical variable'''\n",
    "    \n",
    "    target = target.astype(str).replace({'T':1, 'F':0}, axis =1)\n",
    "    target = target.idxmax(axis = 1)\n",
    "    return target\n",
    "\n",
    "y_train = encode(y_train)\n",
    "y_test = encode(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'labelEncode'  2.66 ms\n",
      "'labelEncode'  8.39 ms\n"
     ]
    }
   ],
   "source": [
    "#label Encoding for creating the array of labeled target variable\n",
    "@timeit\n",
    "def labelEncode(y_train):\n",
    "    \n",
    "    '''defined a function labelEncode\n",
    "    for labeling the target variable'''\n",
    "    \n",
    "    lab_en = LabelEncoder()\n",
    "    return (lab_en.fit_transform(y_train))\n",
    "    \n",
    "\n",
    "y_train = labelEncode(y_train)\n",
    "y_test = labelEncode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vect_model(X_test,y_test,X_train,y_train):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    vect = CountVectorizer(tokenizer=tokenizer.tokenize,      \n",
    "                           stop_words='english',             \n",
    "                           ngram_range=(1, 2), \n",
    "                           max_df=0.5,                        \n",
    "                           min_df=2,\n",
    "                          )\n",
    "    \n",
    "    vect.fit(X_train)\n",
    "    train_dtm = vect.transform(X_train)\n",
    "    test_dtm  = vect.transform(X_test)\n",
    "    \n",
    "    nb = MultinomialNB(alpha=0.25,fit_prior=False)\n",
    "    nb.fit(train_dtm, y_train)\n",
    "    Y_pred_class = nb.predict(test_dtm)\n",
    "    \n",
    "    Y_pred_class1 = nb.predict(test_dtm)\n",
    "    \n",
    "    return metrics.accuracy_score(Y_pred_class1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78910000000000002"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = vect_model(X_test, y_test, X_train, y_train)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
